<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, orientation=landscape">
    <title>Eye Gaze Tracking with Head Pose Estimation</title>
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh/face_mesh.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/camera_utils/camera_utils.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/opencv.js"></script>
    <style>
        body {
            font-family: Arial, sans-serif;
            text-align: center;
            padding: 0;
            margin: 0;
            overflow: hidden;
        }
        video {
            width: 640px;
            height: 480px;
        }
        #gazeDot {
            position: absolute;
            width: 15px;
            height: 15px;
            background-color: red;
            border-radius: 50%;
            z-index: 10;
        }
    </style>
</head>
<body>
    <video id="video" autoplay playsinline></video>
    <div id="gazeDot"></div>

    <script>
        const videoElement = document.getElementById('video');
        const gazeDot = document.getElementById('gazeDot');

        // Load MediaPipe FaceMesh
        const faceMesh = new FaceMesh({
            locateFile: (file) => `https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh/${file}`,
        });

        faceMesh.setOptions({
            maxNumFaces: 1,
            refineLandmarks: true,
            minDetectionConfidence: 0.5,
            minTrackingConfidence: 0.5,
        });

        faceMesh.onResults((results) => {
            if (results.multiFaceLandmarks && results.multiFaceLandmarks.length > 0) {
                const landmarks = results.multiFaceLandmarks[0];

                // נקודות מפתח פנים (אף, עיניים, פה)
                const noseTip = landmarks[1]; 
                const chin = landmarks[152];
                const leftEyeCorner = landmarks[33];
                const rightEyeCorner = landmarks[263];
                const mouthLeft = landmarks[61];
                const mouthRight = landmarks[291];

                // העברת נקודות אלו למודל 3D
                const imagePoints = [
                    [noseTip.x * window.innerWidth, noseTip.y * window.innerHeight],
                    [chin.x * window.innerWidth, chin.y * window.innerHeight],
                    [leftEyeCorner.x * window.innerWidth, leftEyeCorner.y * window.innerHeight],
                    [rightEyeCorner.x * window.innerWidth, rightEyeCorner.y * window.innerHeight],
                    [mouthLeft.x * window.innerWidth, mouthLeft.y * window.innerHeight],
                    [mouthRight.x * window.innerWidth, mouthRight.y * window.innerHeight],
                ];

                // מודל נקודות 3D (כפי שהוזכר במאמר)
                const modelPoints = [
                    [0.0, 0.0, 0.0],          // אף
                    [0.0, -330.0, -65.0],      // סנטר
                    [-225.0, 170.0, -135.0],   // עין שמאל
                    [225.0, 170.0, -135.0],    // עין ימין
                    [-150.0, -150.0, -125.0],  // פה שמאל
                    [150.0, -150.0, -125.0]    // פה ימין
                ];

                // חישוב פתרון PnP
                const focalLength = window.innerWidth;
                const center = [window.innerWidth / 2, window.innerHeight / 2];
                const cameraMatrix = [
                    [focalLength, 0, center[0]],
                    [0, focalLength, center[1]],
                    [0, 0, 1]
                ];
                const distCoeffs = [0, 0, 0, 0];  // הנחה שאין עיוותים בעדשה

                let rotationVector = new cv.Mat();
                let translationVector = new cv.Mat();
                let success = cv.solvePnP(modelPoints, imagePoints, cameraMatrix, distCoeffs, rotationVector, translationVector);

                if (success) {
                    console.log("Rotation Vector: ", rotationVector.data64F);
                    console.log("Translation Vector: ", translationVector.data64F);

                    const projectedPoint = new cv.Mat();
                    cv.projectPoints(cv.matFromArray([0, 0, 1000], cv.CV_64F), rotationVector, translationVector, cameraMatrix, distCoeffs, projectedPoint);

                    const gazeX = projectedPoint.data64F[0];
                    const gazeY = projectedPoint.data64F[1];

                    console.log(`Gaze X: ${gazeX}, Gaze Y: ${gazeY}`);

                    gazeDot.style.left = `${gazeX}px`;
                    gazeDot.style.top = `${gazeY}px`;
                } else {
                    console.error("PnP solution failed.");
                }
            }
        });

        // Start the camera and run the face mesh model on every frame
        const camera = new Camera(videoElement, {
            onFrame: async () => {
                await faceMesh.send({ image: videoElement });
            },
            width: 640,
            height: 480
        });

        camera.start();
    </script>
</body>
</html>
