<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Eye Gaze Direction Tracking with Three.js</title>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/three.js/r128/three.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh/face_mesh.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/camera_utils/camera_utils.js"></script>
    <style>
        body {
            margin: 0;
            overflow: hidden;
        }
        canvas {
            display: block;
        }
    </style>
</head>
<body>
    <video id="video" autoplay playsinline style="display:none;"></video>

    <script>
        // Setup Three.js scene
        const scene = new THREE.Scene();
        const camera = new THREE.PerspectiveCamera(75, window.innerWidth / window.innerHeight, 0.1, 1000);
        const renderer = new THREE.WebGLRenderer();
        renderer.setSize(window.innerWidth, window.innerHeight);
        document.body.appendChild(renderer.domElement);

        // Add gaze tracking dot
        const geometry = new THREE.SphereGeometry(0.05, 32, 32);
        const material = new THREE.MeshBasicMaterial({ color: 0xff0000 });
        const gazeDot = new THREE.Mesh(geometry, material);
        scene.add(gazeDot);

        camera.position.z = 2;

        let previousTimestamp = performance.now();

        // Load MediaPipe FaceMesh
        const faceMesh = new FaceMesh({
            locateFile: (file) => `https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh/${file}`,
        });

        faceMesh.setOptions({
            maxNumFaces: 1,
            refineLandmarks: true,
            minDetectionConfidence: 0.5,
            minTrackingConfidence: 0.5,
        });

        faceMesh.onResults((results) => {
            if (results.multiFaceLandmarks && results.multiFaceLandmarks.length > 0) {
                const landmarks = results.multiFaceLandmarks[0];

                // Get important points: eyes and nose
                const leftEye = landmarks[159];
                const rightEye = landmarks[386];
                const nose = landmarks[1]; // Nose tip

                // Calculate average eye position and direction
                const eyeMidX = (leftEye.x + rightEye.x) / 2;
                const eyeMidY = (leftEye.y + rightEye.y) / 2;

                // Calculate the direction vector (eye center to nose)
                const directionX = nose.x - eyeMidX;
                const directionY = nose.y - eyeMidY;

                // Update gaze dot position based on direction
                const scale = 5; // Scale factor for more noticeable movement
                gazeDot.position.x = directionX * scale;
                gazeDot.position.y = -directionY * scale; // Y-axis inverted
            }
        });

        // Start the camera and run the face mesh model on every frame
        const videoElement = document.getElementById('video');
        const cameraUtils = new Camera(videoElement, {
            onFrame: async () => {
                await faceMesh.send({ image: videoElement });
            },
            width: 640,
            height: 480
        });

        cameraUtils.start();

        // Animate Three.js scene
        function animate() {
            requestAnimationFrame(animate);
            renderer.render(scene, camera);
        }
        animate();
    </script>
</body>
</html>
