<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Eye Gaze Tracking with TensorFlow.js</title>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/facemesh"></script>
    <style>
        body {
            margin: 0;
            overflow: hidden;
        }
        canvas {
            display: block;
        }
        #gaze-dot {
            position: absolute;
            width: 15px;
            height: 15px;
            background-color: red;
            border-radius: 50%;
        }
    </style>
</head>
<body>
    <video id="video" autoplay playsinline></video>
    <div id="gaze-dot"></div>

    <script>
        const video = document.getElementById('video');
        const gazeDot = document.getElementById('gaze-dot');

        // Setup the video stream
        async function setupCamera() {
            const stream = await navigator.mediaDevices.getUserMedia({ video: true });
            video.srcObject = stream;

            return new Promise((resolve) => {
                video.onloadedmetadata = () => {
                    resolve(video);
                };
            });
        }

        // Load TensorFlow FaceMesh model
        async function loadModel() {
            const model = await facemesh.load();
            console.log('FaceMesh model loaded');
            return model;
        }

        async function detectFace(model) {
            const predictions = await model.estimateFaces(video);

            if (predictions.length > 0) {
                const keypoints = predictions[0].scaledMesh;

                if (keypoints[468] && keypoints[473]) {
                    const leftPupil = keypoints[468];
                    const rightPupil = keypoints[473];

                    console.log("Left Pupil:", leftPupil); // Log pupil coordinates
                    console.log("Right Pupil:", rightPupil);

                    // Calculate the average position of the pupils
                    const avgPupilX = (leftPupil[0] + rightPupil[0]) / 2;
                    const avgPupilY = (leftPupil[1] + rightPupil[1]) / 2;

                    // Update gaze dot position based on pupil location
                    gazeDot.style.left = `${avgPupilX - 7}px`;
                    gazeDot.style.top = `${avgPupilY - 7}px`;
                } else {
                    console.log('Pupil keypoints not found.');
                }
            } else {
                console.log('No face detected');
            }
        }

        // Main function to run the tracking
        async function run() {
            await setupCamera();
            const model = await loadModel();
            video.play();

            // Continuously run face detection
            setInterval(() => detectFace(model), 100);
        }

        run();
    </script>
</body>
</html>
